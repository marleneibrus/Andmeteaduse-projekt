{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb7c654",
   "metadata": {},
   "source": [
    "# DATA SCIENCE PROJECT E9\n",
    "## KAGGLE - Stanford Ribonanza RNA Folding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "944c4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import platform\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import shutil\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "960cbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fadb1aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1643680, 419)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>experiment_type</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>reads</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>reactivity_0001</th>\n",
       "      <th>reactivity_0002</th>\n",
       "      <th>reactivity_0003</th>\n",
       "      <th>...</th>\n",
       "      <th>reactivity_error_0197</th>\n",
       "      <th>reactivity_error_0198</th>\n",
       "      <th>reactivity_error_0199</th>\n",
       "      <th>reactivity_error_0200</th>\n",
       "      <th>reactivity_error_0201</th>\n",
       "      <th>reactivity_error_0202</th>\n",
       "      <th>reactivity_error_0203</th>\n",
       "      <th>reactivity_error_0204</th>\n",
       "      <th>reactivity_error_0205</th>\n",
       "      <th>reactivity_error_0206</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8cdfeef009ea</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>2343</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51e61fbde94d</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>5326</td>\n",
       "      <td>1.933</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25ce8d5109cd</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>4647</td>\n",
       "      <td>2.347</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07dcfb6d1965</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>102843</td>\n",
       "      <td>11.824</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e561cc042a4c</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...</td>\n",
       "      <td>2A3_MaP</td>\n",
       "      <td>15k_2A3</td>\n",
       "      <td>7665</td>\n",
       "      <td>3.519</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 419 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id                                           sequence  \\\n",
       "0  8cdfeef009ea  GGGAACGACUCGAGUAGAGUCGAAAAACGUUGAUAUGGAUUUACUC...   \n",
       "1  51e61fbde94d  GGGAACGACUCGAGUAGAGUCGAAAAACAUUGAUAUGGAUUUACUC...   \n",
       "2  25ce8d5109cd  GGGAACGACUCGAGUAGAGUCGAAAAACCUUGAUAUGGAUUUACUC...   \n",
       "3  07dcfb6d1965  GGGAACGACUCGAGUAGAGUCGAAAAACUUUGAUAUGGAUUUACUC...   \n",
       "4  e561cc042a4c  GGGAACGACUCGAGUAGAGUCGAAAAACGAUGAUAUGGAUUUACUC...   \n",
       "\n",
       "  experiment_type dataset_name   reads  signal_to_noise  SN_filter  \\\n",
       "0         2A3_MaP      15k_2A3    2343            0.944          0   \n",
       "1         2A3_MaP      15k_2A3    5326            1.933          1   \n",
       "2         2A3_MaP      15k_2A3    4647            2.347          1   \n",
       "3         2A3_MaP      15k_2A3  102843           11.824          1   \n",
       "4         2A3_MaP      15k_2A3    7665            3.519          1   \n",
       "\n",
       "   reactivity_0001  reactivity_0002  reactivity_0003  ...  \\\n",
       "0              NaN              NaN              NaN  ...   \n",
       "1              NaN              NaN              NaN  ...   \n",
       "2              NaN              NaN              NaN  ...   \n",
       "3              NaN              NaN              NaN  ...   \n",
       "4              NaN              NaN              NaN  ...   \n",
       "\n",
       "   reactivity_error_0197  reactivity_error_0198  reactivity_error_0199  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0200  reactivity_error_0201  reactivity_error_0202  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0203  reactivity_error_0204  reactivity_error_0205  \\\n",
       "0                    NaN                    NaN                    NaN   \n",
       "1                    NaN                    NaN                    NaN   \n",
       "2                    NaN                    NaN                    NaN   \n",
       "3                    NaN                    NaN                    NaN   \n",
       "4                    NaN                    NaN                    NaN   \n",
       "\n",
       "   reactivity_error_0206  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  \n",
       "\n",
       "[5 rows x 419 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_parquet('train_data.parquet')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c2b1dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1943947\n"
     ]
    }
   ],
   "source": [
    "print(train[\"signal_to_noise\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20098f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import shutil\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9270881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "policyConfig = 'mixed_bfloat16'\n",
    "policy = tf.keras.mixed_precision.Policy(policyConfig)\n",
    "tf.keras.mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59a68b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu = None\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"on TPU\")\n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a6c757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tffiles_path = 'tfrfile'\n",
    "tffiles = ['{}/{:03d}.tfrecord'.format(tffiles_path, idx) for idx  in range(164)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e005d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_tfrec(record_bytes):\n",
    "    schema = {}\n",
    "    schema[\"id\"] = tf.io.VarLenFeature(dtype=tf.string)\n",
    "    schema[\"seq\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
    "    schema[\"dataset_name_2A3\"] = tf.io.VarLenFeature(dtype=tf.string)\n",
    "    schema[\"dataset_name_DMS\"] = tf.io.VarLenFeature(dtype=tf.string)\n",
    "    schema[\"reactivity_2A3\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
    "    schema[\"reactivity_DMS\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
    "    schema[\"reactivity_error_2A3\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
    "    schema[\"reactivity_error_DMS\"] = tf.io.VarLenFeature(dtype=tf.float32)\n",
    "    features = tf.io.parse_single_example(record_bytes, schema)\n",
    "\n",
    "    sample_id = tf.sparse.to_dense(features[\"id\"])\n",
    "    seq = tf.sparse.to_dense(features[\"seq\"])\n",
    "    dataset_name_2A3 = tf.sparse.to_dense(features[\"dataset_name_2A3\"])\n",
    "    dataset_name_DMS = tf.sparse.to_dense(features[\"dataset_name_DMS\"])\n",
    "    reactivity_2A3 = tf.sparse.to_dense(features[\"reactivity_2A3\"])\n",
    "    reactivity_DMS = tf.sparse.to_dense(features[\"reactivity_DMS\"])\n",
    "    reactivity_error_2A3 = tf.sparse.to_dense(features[\"reactivity_error_2A3\"])\n",
    "    reactivity_error_DMS = tf.sparse.to_dense(features[\"reactivity_error_DMS\"])\n",
    "\n",
    "    out = {}\n",
    "    out['seq']  = seq\n",
    "    out['reactivity_2A3']  = reactivity_2A3\n",
    "    out['reactivity_DMS']  = reactivity_DMS\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97abd242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_target(x):\n",
    "    reactivity_2A3 = x['reactivity_2A3']\n",
    "    reactivity_DMS = x['reactivity_DMS']\n",
    "    target = tf.concat([reactivity_2A3[..., tf.newaxis], reactivity_DMS[..., tf.newaxis]], axis = 1)\n",
    "    target = tf.clip_by_value(target, 0, 1)\n",
    "    return x['seq'], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efccaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False # A boolean variable, to check if our model is in debugging mode\n",
    " \n",
    "PAD_x = 0.0\n",
    "PAD_y = np.nan\n",
    "X_max_len = 206\n",
    "batch_size = 256\n",
    "val_batch_size = 5120\n",
    "\n",
    "\n",
    "if DEBUG:\n",
    "    batch_size = 2\n",
    "    val_batch_size = 2\n",
    "\n",
    "num_vocab = 5\n",
    "hidden_dim = 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30f79d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/zulqarnainali/explained-transformer-tpu-inference/notebook\n",
    "class transformer_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=dim//num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.supports_masking = True\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training, mask):\n",
    "        att_mask = tf.expand_dims(mask, axis=-1)\n",
    "        att_mask = tf.repeat(att_mask, repeats=tf.shape(att_mask)[1], axis=-1)\n",
    "\n",
    "        attn_output = self.att(inputs, inputs, attention_mask = att_mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class positional_encoding_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_vocab=5, maxlen=500, hidden_dim=384):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.pos_emb = self.positional_encoding(maxlen-1, hidden_dim)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.cast(x, dtype=tf.float32)  # Ensure input is cast to float32\n",
    "        x = x * tf.math.sqrt(tf.cast(self.hidden_dim, tf.float32))\n",
    "        maxlen = tf.shape(x)[-2]\n",
    "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.hidden_dim, tf.float32)))\n",
    "        return x + self.pos_emb[:maxlen, :]\n",
    "\n",
    "    def positional_encoding(self, maxlen, hidden_dim, ):\n",
    "        depth = hidden_dim/2\n",
    "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
    "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
    "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
    "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
    "        pos_encoding = tf.concat(\n",
    "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
    "          axis=-1)\n",
    "        return pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e5f0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfrec_dataset(tffiles, shuffle, batch_size, cache = False, calculate_sample_num = True, to_repeat = False):\n",
    "    ds = tf.data.TFRecordDataset(\n",
    "        tffiles, num_parallel_reads=tf.data.AUTOTUNE, compression_type = 'GZIP').prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    ds = ds.map(decode_tfrec, tf.data.AUTOTUNE)\n",
    "    ds = ds.map(concat_target, tf.data.AUTOTUNE)\n",
    "\n",
    "    if DEBUG:\n",
    "        ds = ds.take(8)\n",
    "\n",
    "    if cache:\n",
    "        ds = ds.cache()\n",
    "\n",
    "    samples_num = 0\n",
    "    if calculate_sample_num:\n",
    "        samples_num = ds.reduce(0, lambda x,_: x+1).numpy()        \n",
    "\n",
    "    if shuffle:\n",
    "        if shuffle == -1:\n",
    "            ds = ds.shuffle(samples_num, reshuffle_each_iteration = True)\n",
    "        else:\n",
    "            ds = ds.shuffle(shuffle, reshuffle_each_iteration = True)\n",
    "\n",
    "    if to_repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    \n",
    "    if batch_size:\n",
    "        ds = ds.padded_batch(\n",
    "            batch_size, padding_values=(PAD_x, PAD_y), padded_shapes=([X_max_len],[X_max_len, 2]), drop_remainder=True)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds, samples_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ed39a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_len = 5\n",
    "if DEBUG:\n",
    "    val_len = 1\n",
    "\n",
    "val_files = tffiles[:val_len]\n",
    "\n",
    "if DEBUG:\n",
    "    train_files = tffiles[val_len:val_len+1]\n",
    "else:\n",
    "    train_files = tffiles[val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c4b2712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tfrfile/005.tfrecord', 'tfrfile/006.tfrecord', 'tfrfile/007.tfrecord', 'tfrfile/008.tfrecord', 'tfrfile/009.tfrecord', 'tfrfile/010.tfrecord', 'tfrfile/011.tfrecord', 'tfrfile/012.tfrecord', 'tfrfile/013.tfrecord', 'tfrfile/014.tfrecord', 'tfrfile/015.tfrecord', 'tfrfile/016.tfrecord', 'tfrfile/017.tfrecord', 'tfrfile/018.tfrecord', 'tfrfile/019.tfrecord', 'tfrfile/020.tfrecord', 'tfrfile/021.tfrecord', 'tfrfile/022.tfrecord', 'tfrfile/023.tfrecord', 'tfrfile/024.tfrecord', 'tfrfile/025.tfrecord', 'tfrfile/026.tfrecord', 'tfrfile/027.tfrecord', 'tfrfile/028.tfrecord', 'tfrfile/029.tfrecord', 'tfrfile/030.tfrecord', 'tfrfile/031.tfrecord', 'tfrfile/032.tfrecord', 'tfrfile/033.tfrecord', 'tfrfile/034.tfrecord', 'tfrfile/035.tfrecord', 'tfrfile/036.tfrecord', 'tfrfile/037.tfrecord', 'tfrfile/038.tfrecord', 'tfrfile/039.tfrecord', 'tfrfile/040.tfrecord', 'tfrfile/041.tfrecord', 'tfrfile/042.tfrecord', 'tfrfile/043.tfrecord', 'tfrfile/044.tfrecord', 'tfrfile/045.tfrecord', 'tfrfile/046.tfrecord', 'tfrfile/047.tfrecord', 'tfrfile/048.tfrecord', 'tfrfile/049.tfrecord', 'tfrfile/050.tfrecord', 'tfrfile/051.tfrecord', 'tfrfile/052.tfrecord', 'tfrfile/053.tfrecord', 'tfrfile/054.tfrecord', 'tfrfile/055.tfrecord', 'tfrfile/056.tfrecord', 'tfrfile/057.tfrecord', 'tfrfile/058.tfrecord', 'tfrfile/059.tfrecord', 'tfrfile/060.tfrecord', 'tfrfile/061.tfrecord', 'tfrfile/062.tfrecord', 'tfrfile/063.tfrecord', 'tfrfile/064.tfrecord', 'tfrfile/065.tfrecord', 'tfrfile/066.tfrecord', 'tfrfile/067.tfrecord', 'tfrfile/068.tfrecord', 'tfrfile/069.tfrecord', 'tfrfile/070.tfrecord', 'tfrfile/071.tfrecord', 'tfrfile/072.tfrecord', 'tfrfile/073.tfrecord', 'tfrfile/074.tfrecord', 'tfrfile/075.tfrecord', 'tfrfile/076.tfrecord', 'tfrfile/077.tfrecord', 'tfrfile/078.tfrecord', 'tfrfile/079.tfrecord', 'tfrfile/080.tfrecord', 'tfrfile/081.tfrecord', 'tfrfile/082.tfrecord', 'tfrfile/083.tfrecord', 'tfrfile/084.tfrecord', 'tfrfile/085.tfrecord', 'tfrfile/086.tfrecord', 'tfrfile/087.tfrecord', 'tfrfile/088.tfrecord', 'tfrfile/089.tfrecord', 'tfrfile/090.tfrecord', 'tfrfile/091.tfrecord', 'tfrfile/092.tfrecord', 'tfrfile/093.tfrecord', 'tfrfile/094.tfrecord', 'tfrfile/095.tfrecord', 'tfrfile/096.tfrecord', 'tfrfile/097.tfrecord', 'tfrfile/098.tfrecord', 'tfrfile/099.tfrecord', 'tfrfile/100.tfrecord', 'tfrfile/101.tfrecord', 'tfrfile/102.tfrecord', 'tfrfile/103.tfrecord', 'tfrfile/104.tfrecord', 'tfrfile/105.tfrecord', 'tfrfile/106.tfrecord', 'tfrfile/107.tfrecord', 'tfrfile/108.tfrecord', 'tfrfile/109.tfrecord', 'tfrfile/110.tfrecord', 'tfrfile/111.tfrecord', 'tfrfile/112.tfrecord', 'tfrfile/113.tfrecord', 'tfrfile/114.tfrecord', 'tfrfile/115.tfrecord', 'tfrfile/116.tfrecord', 'tfrfile/117.tfrecord', 'tfrfile/118.tfrecord', 'tfrfile/119.tfrecord', 'tfrfile/120.tfrecord', 'tfrfile/121.tfrecord', 'tfrfile/122.tfrecord', 'tfrfile/123.tfrecord', 'tfrfile/124.tfrecord', 'tfrfile/125.tfrecord', 'tfrfile/126.tfrecord', 'tfrfile/127.tfrecord', 'tfrfile/128.tfrecord', 'tfrfile/129.tfrecord', 'tfrfile/130.tfrecord', 'tfrfile/131.tfrecord', 'tfrfile/132.tfrecord', 'tfrfile/133.tfrecord', 'tfrfile/134.tfrecord', 'tfrfile/135.tfrecord', 'tfrfile/136.tfrecord', 'tfrfile/137.tfrecord', 'tfrfile/138.tfrecord', 'tfrfile/139.tfrecord', 'tfrfile/140.tfrecord', 'tfrfile/141.tfrecord', 'tfrfile/142.tfrecord', 'tfrfile/143.tfrecord', 'tfrfile/144.tfrecord', 'tfrfile/145.tfrecord', 'tfrfile/146.tfrecord', 'tfrfile/147.tfrecord', 'tfrfile/148.tfrecord', 'tfrfile/149.tfrecord', 'tfrfile/150.tfrecord', 'tfrfile/151.tfrecord', 'tfrfile/152.tfrecord', 'tfrfile/153.tfrecord', 'tfrfile/154.tfrecord', 'tfrfile/155.tfrecord', 'tfrfile/156.tfrecord', 'tfrfile/157.tfrecord', 'tfrfile/158.tfrecord', 'tfrfile/159.tfrecord', 'tfrfile/160.tfrecord', 'tfrfile/161.tfrecord', 'tfrfile/162.tfrecord', 'tfrfile/163.tfrecord']\n"
     ]
    }
   ],
   "source": [
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89ccb9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162688\n",
      "5120\n"
     ]
    }
   ],
   "source": [
    "train_dataset, num_train = get_tfrec_dataset(train_files, shuffle = -1, batch_size = batch_size,\n",
    "                                                  cache = True, calculate_sample_num = True,\n",
    "                                            to_repeat = True)\n",
    "\n",
    "val_dataset, num_val = get_tfrec_dataset(val_files, shuffle = False, batch_size = val_batch_size,\n",
    "                                                  cache = True, calculate_sample_num = True)\n",
    "print(num_train)\n",
    "print(num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e00c5b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([5120, 206]), TensorShape([5120, 206, 2]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(val_dataset))\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0cee3548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/zulqarnainali/explained-transformer-tpu-inference/notebook\n",
    "\n",
    "def get_model(hidden_dim = 384, max_len = 206):\n",
    "    inp = tf.keras.Input([None])\n",
    "    x = inp\n",
    "\n",
    "    x = tf.keras.layers.Embedding(num_vocab, hidden_dim, mask_zero=True)(x)\n",
    "    x = positional_encoding_layer(num_vocab=num_vocab, maxlen=500, hidden_dim=hidden_dim)(x)\n",
    "\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(2)(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1be27369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(labels, targets):\n",
    "    labels_mask = tf.math.is_nan(labels)\n",
    "    labels = tf.where(labels_mask, tf.zeros_like(labels), labels)\n",
    "    mask_count = tf.math.reduce_sum(tf.where(labels_mask, tf.zeros_like(labels), tf.ones_like(labels)))\n",
    "    loss = tf.math.abs(labels - targets)\n",
    "    loss = tf.where(labels_mask, tf.zeros_like(loss), loss)\n",
    "    loss = tf.math.reduce_sum(loss)/mask_count\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f644d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25547"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c887e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_dim = 384, max_len = 206):\n",
    "    with strategy.scope():\n",
    "        inp = tf.keras.Input([max_len])\n",
    "        x = inp\n",
    "\n",
    "        x = tf.keras.layers.Embedding(num_vocab, hidden_dim, mask_zero=True)(x)\n",
    "        x = positional_encoding_layer(num_vocab=num_vocab, maxlen=500, hidden_dim=hidden_dim)(x)\n",
    "\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "        x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "        x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        x = tf.keras.layers.Dense(2)(x)\n",
    "\n",
    "        model = tf.keras.Model(inp, x)\n",
    "        loss = loss_fn\n",
    "        if platform.system() == \"Darwin\" and platform.processor() == \"arm\":\n",
    "            optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0005)\n",
    "        else:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "        # optimizer = tf.keras.optimizers.AdamW(learning_rate=0.0005) # The non legacy AdamW runs slow on M2 (my computer)\n",
    "        model.compile(loss=loss, optimizer=optimizer, steps_per_execution = 100)\n",
    "        return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model(hidden_dim = 192,max_len = X_max_len)\n",
    "model(batch[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d92c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 200\n",
    "if DEBUG:\n",
    "    N_EPOCHS = 5\n",
    "N_WARMUP_EPOCHS = 0\n",
    "LR_MAX = 5e-4\n",
    "WD_RATIO = 0.05\n",
    "WARMUP_METHOD = \"exp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc2f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrfn(current_step, num_warmup_steps, lr_max, num_cycles=0.50, num_training_steps=N_EPOCHS):\n",
    "    if current_step < num_warmup_steps:\n",
    "        if WARMUP_METHOD == 'log':\n",
    "            return lr_max * 0.10 ** (num_warmup_steps - current_step)\n",
    "        else:\n",
    "            return lr_max * 2 ** -(num_warmup_steps - current_step)\n",
    "    else:\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr_max\n",
    "\n",
    "def plot_lr_schedule(lr_schedule, epochs):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.plot([None] + lr_schedule + [None])\n",
    "    # X Labels\n",
    "    x = np.arange(1, epochs + 1)\n",
    "    x_axis_labels = [i if epochs <= 40 or i % 5 == 0 or i == 1 else None for i in range(1, epochs + 1)]\n",
    "    plt.xlim([1, epochs])\n",
    "    plt.xticks(x, x_axis_labels) # set tick step to 1 and let x axis start at 1\n",
    "\n",
    "    # Increase y-limit for better readability\n",
    "    plt.ylim([0, max(lr_schedule) * 1.1])\n",
    "\n",
    "    # Title\n",
    "    schedule_info = f'start: {lr_schedule[0]:.1E}, max: {max(lr_schedule):.1E}, final: {lr_schedule[-1]:.1E}'\n",
    "    plt.title(f'Step Learning Rate Schedule, {schedule_info}', size=18, pad=12)\n",
    "\n",
    "    # Plot Learning Rates\n",
    "    for x, val in enumerate(lr_schedule):\n",
    "        if epochs <= 40 or x % 5 == 0 or x is epochs - 1:\n",
    "            if x < len(lr_schedule) - 1:\n",
    "                if lr_schedule[x - 1] < val:\n",
    "                    ha = 'right'\n",
    "                else:\n",
    "                    ha = 'left'\n",
    "            elif x == 0:\n",
    "                ha = 'right'\n",
    "            else:\n",
    "                ha = 'left'\n",
    "            plt.plot(x + 1, val, 'o', color='black');\n",
    "            offset_y = (max(lr_schedule) - min(lr_schedule)) * 0.02\n",
    "            plt.annotate(f'{val:.1E}', xy=(x + 1, val + offset_y), size=12, ha=ha)\n",
    "\n",
    "    plt.xlabel('Epoch', size=16, labelpad=5)\n",
    "    plt.ylabel('Learning Rate', size=16, labelpad=5)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Learning rate for encoder\n",
    "LR_SCHEDULE = [lrfn(step, num_warmup_steps=N_WARMUP_EPOCHS, lr_max=LR_MAX, num_cycles=0.50) for step in range(N_EPOCHS)]\n",
    "# Plot Learning Rate Schedule\n",
    "plot_lr_schedule(LR_SCHEDULE, epochs=N_EPOCHS)\n",
    "# Learning Rate Callback\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda step: LR_SCHEDULE[step], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eceae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = 'model_weights'\n",
    "try:\n",
    "    os.mkdir(f'{save_folder}')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "class save_model_callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        if epoch == 3 or (epoch+1)%25 == 0:\n",
    "            self.model.save_weights(f\"{save_folder}/model_epoch_{epoch}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3b54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = num_train//batch_size\n",
    "val_steps_per_epoch = num_val//val_batch_size\n",
    "print(steps_per_epoch)\n",
    "print(val_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=N_EPOCHS,\n",
    "    steps_per_epoch = steps_per_epoch,\n",
    "    validation_steps=val_steps_per_epoch,\n",
    "    verbose = 2,\n",
    "    callbacks=[\n",
    "        save_model_callback(),\n",
    "        lr_callback,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
