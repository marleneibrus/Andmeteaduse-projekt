{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6df1f6",
   "metadata": {},
   "source": [
    "# Inference notebook \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2021da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ppind\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import shutil\n",
    "import math\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a14531a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1343823, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_min</th>\n",
       "      <th>id_max</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>future</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>eee73c1836bc</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUUUCCUUCCAAAUCCUGAGG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177</td>\n",
       "      <td>353</td>\n",
       "      <td>d2a929af7a97</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUGUAAUCAGAUUGCUUCUCC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>354</td>\n",
       "      <td>530</td>\n",
       "      <td>d39a4425ff45</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAAACACAUGAAUUUGAGGGUU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>531</td>\n",
       "      <td>707</td>\n",
       "      <td>1fc41e92d553</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUCAGAGCUGGCAAAUGGAUG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>708</td>\n",
       "      <td>884</td>\n",
       "      <td>1d0826fb892f</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUUUGGUAUUUGAUGCAUUAA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_min  id_max   sequence_id  \\\n",
       "0       0     176  eee73c1836bc   \n",
       "1     177     353  d2a929af7a97   \n",
       "2     354     530  d39a4425ff45   \n",
       "3     531     707  1fc41e92d553   \n",
       "4     708     884  1d0826fb892f   \n",
       "\n",
       "                                            sequence  future  \n",
       "0  GGGAACGACUCGAGUAGAGUCGAAAAUUUCCUUCCAAAUCCUGAGG...       0  \n",
       "1  GGGAACGACUCGAGUAGAGUCGAAAAUGUAAUCAGAUUGCUUCUCC...       0  \n",
       "2  GGGAACGACUCGAGUAGAGUCGAAAAAACACAUGAAUUUGAGGGUU...       0  \n",
       "3  GGGAACGACUCGAGUAGAGUCGAAAAUCAGAGCUGGCAAAUGGAUG...       0  \n",
       "4  GGGAACGACUCGAGUAGAGUCGAAAAUUUGGUAUUUGAUGCAUUAA...       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_parquet('test_sequences.parquet')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b415735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 1, 'C': 2, 'G': 3, 'U': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sequences = test.sequence.to_numpy()\n",
    "encoding_dict = {'A':1, 'C': 2, 'G': 3, 'U': 4}\n",
    "encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010e7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c5701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 457 \n",
    "test_sequences_encoded = []\n",
    "for seq in test_sequences:\n",
    "    test_sequences_encoded.append(\n",
    "        np.concatenate([np.asarray([encoding_dict[x] for x in seq]), np.zeros((max_len - len(seq)))]).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70511a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([256, 457])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices(test_sequences_encoded)\n",
    "batch_size = 256\n",
    "if DEBUG:\n",
    "    test_ds = test_ds.take(8)\n",
    "    batch_size = 2\n",
    "#test_ds = test_ds.take(10000)\n",
    "\n",
    "test_ds = test_ds.padded_batch(batch_size, padding_values=(0.0), padded_shapes=([max_len]), drop_remainder=False)\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "batch = next(iter(test_ds))\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ed15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer_block(tf.keras.layers.Layer):\n",
    "    def __init__(self, dim, num_heads, feed_forward_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=dim//num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "                tf.keras.layers.Dense(dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, training, mask):\n",
    "        att_mask = tf.expand_dims(mask, axis=-1)\n",
    "        att_mask = tf.repeat(att_mask, repeats=tf.shape(att_mask)[1], axis=-1)\n",
    "\n",
    "        attn_output = self.att(inputs, inputs, attention_mask = att_mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "\n",
    "class positional_encoding_layer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_vocab=5, maxlen=500, hidden_dim=384):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.pos_emb = self.positional_encoding(maxlen-1, hidden_dim)\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-2]\n",
    "        x = tf.math.multiply(x, tf.math.sqrt(tf.cast(self.hidden_dim, tf.float32)))\n",
    "        return x + self.pos_emb[:maxlen, :]\n",
    "\n",
    "    def positional_encoding(self, maxlen, hidden_dim):\n",
    "        depth = hidden_dim/2\n",
    "        positions = tf.range(maxlen, dtype = tf.float32)[..., tf.newaxis]\n",
    "        depths = tf.range(depth, dtype = tf.float32)[np.newaxis, :]/depth\n",
    "        angle_rates = tf.math.divide(1, tf.math.pow(tf.cast(10000, tf.float32), depths))\n",
    "        angle_rads = tf.linalg.matmul(positions, angle_rates)\n",
    "        pos_encoding = tf.concat(\n",
    "          [tf.math.sin(angle_rads), tf.math.cos(angle_rads)],\n",
    "          axis=-1)\n",
    "        return pos_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2546308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max_len = 457\n",
    "num_vocab = 5\n",
    "\n",
    "def get_model(hidden_dim = 384, max_len = 206):\n",
    "    inp = tf.keras.Input([None])\n",
    "    x = inp\n",
    "\n",
    "    x = tf.keras.layers.Embedding(num_vocab, hidden_dim, mask_zero=True)(x)\n",
    "    x = positional_encoding_layer(num_vocab=num_vocab, maxlen=500, hidden_dim=hidden_dim)(x)\n",
    "\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "    x = transformer_block(hidden_dim, 6, hidden_dim*4)(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(2)(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83239254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 192)         960       \n",
      "                                                                 \n",
      " positional_encoding_layer_  (None, None, 192)         0         \n",
      " 1 (positional_encoding_lay                                      \n",
      " er)                                                             \n",
      "                                                                 \n",
      " transformer_block_12 (tran  (None, None, 192)         444864    \n",
      " sformer_block)                                                  \n",
      "                                                                 \n",
      " transformer_block_13 (tran  (None, None, 192)         444864    \n",
      " sformer_block)                                                  \n",
      "                                                                 \n",
      " transformer_block_14 (tran  (None, None, 192)         444864    \n",
      " sformer_block)                                                  \n",
      "                                                                 \n",
      " transformer_block_15 (tran  (None, None, 192)         444864    \n",
      " sformer_block)                                                  \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, None, 192)         0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, None, 2)           386       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1780802 (6.79 MB)\n",
      "Trainable params: 1780802 (6.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(hidden_dim = 192,max_len = max_len)\n",
    "model.load_weights('model_weights/model_epoch_3.h5') \n",
    "#asendada Ãµige failinimega\n",
    "model(batch)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8757c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  19/5250 [..............................] - ETA: 13:01:36"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4affa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_processed = []\n",
    "for i, pred in enumerate(preds):\n",
    "    preds_processed.append(pred[:len(test_sequences[i])])\n",
    "concat_preds = np.concatenate(preds_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d26f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id':np.arange(0, len(concat_preds), 1), 'reactivity_DMS_MaP':concat_preds[:,1], 'reactivity_2A3_MaP':concat_preds[:,0]})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162559e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
